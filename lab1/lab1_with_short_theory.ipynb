{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Лабораторный практикум по курсу «Распознавание диктора», Университет ИТМО, 2021**\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лабораторная работа №1. Информативные признаки речевых сигналов: извлечение признаков**\n",
    "\n",
    "**Цель работы:** изучение процедуры построения информативных акустических признаков для речевых сигналов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание лабораторной работы**\n",
    "\n",
    "1. Выполнить процедуру высокочастотной фильтрации (преэмфазис) речевого сигнала.\n",
    "\n",
    "2. Вычислить акустические признаки разных видов.\n",
    "\n",
    "3. Выполнить локальные центрирование и масштабирование акустических признаков.\n",
    "\n",
    "4. Построить распределение первых 3 компонент полученных акустических признаков для мужских и женских голосов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "\n",
    "from common import download_dataset, extract_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Подготовка данных для обучения и тестирования детектора речевой активности**\n",
    "\n",
    "В ходе выполнения лабораторной работы необходимы данные для осуществления процедуры вычисления акустических признаков. Возьмём в качестве этих данных несколько звукозаписей голосов людей мужского и женского пола, сохраненных в формат *wav*, выбранных из корпуса [VoxCeleb1 test set](https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip). Данный корпус содержит 4,874 звукозаписи (частота дискретизации равна 16кГц) 40 дикторов мужского и женского пола, разговаривающих на английском языке.\n",
    "\n",
    "В рамках настоящего пункта требуется выполнить загрузку и распаковку звуковых wav-файлов из корпуса VoxCeleb1 test set.\n",
    "\n",
    "![Рисунок 1](https://analyticsindiamag.com/wp-content/uploads/2020/12/image.png \"VoxCeleb. Крупномасштабная аудиовизуальная база данных человеческой речи.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checksum successful vox1_test_wav.zip.\n"
     ]
    }
   ],
   "source": [
    "# Download VoxCeleb1 (test set)\n",
    "with open('../data/lists/datasets.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "download_dataset(lines, user='voxceleb1902', password='nx0bl2v2', save_path='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting of ../data/vox1_test_wav.zip is successful.\n"
     ]
    }
   ],
   "source": [
    "# Extract VoxCeleb1 test set\n",
    "extract_dataset(save_path='../data/voxceleb1_test', fname='../data/vox1_test_wav.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Выполнить процедуру высокочастотной фильтрации (преэмфазис) речевого сигнала**\n",
    "\n",
    "В рамках настоящего пункта предлагается изучить процедуру предобработки речевых сигналов, получившую название преэмфазис. *Преэмфазис (pre-emphasis)* – применение фильтра верхних частот к сигналу до процедуры извлечения признаков для того, чтобы компенсировать тот факт, что обычно вокализованная речь содержит на низких частотах намного больше энергии, чем невокализованная речь на высоких. Обозначим через $x(n)$ обрабатываемый сигнал, а через $y(n)$ результат обработки, тогда процедура преэмфазиса может быть описана с помощью следующего выражения:\n",
    "\n",
    "$$y(n) = x(n) + \\alpha x(n-1).$$\n",
    "\n",
    "Выражение выше представляет собой *линейное разностное уравнение с постоянными коэффициентами* и позволяет описать процедуру работы *нерекурсивного фильтра первого порядка с конечной импульсной характеристикой*. Параметр $\\alpha$ является единственным параметром рассматриваемого фильтра. В случае, когда параметр $\\alpha$ является отрицательным, фильтр рассматриваемый фильтр обладает свойствами *фильтра верхних частот*. Для выполнения процедуры преэмфазиса параметр $\\alpha$ обычно выбирается равным величине $-0.97$.\n",
    "\n",
    "В рамках настоящего пункта требуется:\n",
    "\n",
    "1. Загрузить анализируемый речевой сигнал.\n",
    "\n",
    "2. Выполнить процедуру преэмфазиса по отношению к загруженному речевому сигналу.\n",
    "\n",
    "3. Сравнить спектры речевых сигналов до и после процедуры преэмфазиса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Вычислить акустические признаки разных видов**\n",
    "\n",
    "Работа современных систем голосовой биометрии, как правило, является основанной на использовании акустических признаков. *Акустические признаки* являются формой представления речевого сигнала в частотно-временной области. Возможным примером акустических признаков является *спектрограмма* сигнала, которую можно вычислить с использованием *оконного преобразования Фурье*. Однако, использование спектрограммы на практике не является выгодным, в частности, из-за её большого разрешения по частоте. Поэтому возможным вариантом для построения акустических признаков могут являться: *логарифмов энергий на выходе мел-банка фильтров*, *мел-частотные кепстральные коэффициенты размерности* и т.п.\n",
    "\n",
    "В рамках настоящего пункта предлагается вычислить логарифмы энергий на выходе мел-банка фильтров размерности 40 и мел-частотные кепстральные коэффициенты размерности 23. Для выполнения задания выше можно воспользоваться следующим алгоритмом:\n",
    "\n",
    "1. Представить обрабатываемый речевой сигнал в виде набора фреймов с использованием *окна Хэмминга* (размер окна можно выбрать равным 25мс, а шаг окна – 10мс).\n",
    "\n",
    "2. Вычислить одномерный спектр Фурье по отношению к каждому из фреймов.\n",
    "\n",
    "3. Рассчитать мел-банк фильтров.\n",
    "\n",
    "4. Перемножить квадрат *амплитудно-частотной характеристики (АЧХ)* каждого фильтра со спектром мощности каждого из фреймов ⁡и просуммировать коэффициенты получившихся спектров, рассчитав энергии внутри соответствующих полос банка фильтров.\n",
    "\n",
    "5. Вычислить логарифм от значений энергий на предыдущем шаге. *На этом шаги формируется первый тип акустических признаков.*\n",
    "\n",
    "6. Вычислить дискретное косинусное преобразование от логарифмов коэффициентов. *На этом этапе формируются мел-частотные кепстральные коэффициенты.*\n",
    "\n",
    "Подробное описание процедуры вычисления акустических признаков можно найти по следующей [ссылке](http://practicalcryptography.com/miscellaneous/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Выполнить локальные центрирование и масштабирование акустических признаков**\n",
    "\n",
    "Канал связи может вносит некоторое смещение в захваченный сигнал (микрофон может не иметь равномерную АЧХ, изменения в усилении\n",
    "сигнал приводят к вычислению различных акустических признаков даже для одного и того же куска речи). Канальный эффект можно промоделировать с использованием линейного инвариантного к сдвигу фильтра (ЛИС-фильтра) и учесть при корректировке значений акустических признаков. Данная процедура получила название *процедуры нормализации*.\n",
    "\n",
    "Идея выполнения процедуры нормализации состоит в вычислении среднего вектора наблюдаемых акустических признаков и центрирования всех векторов акустических признаков произнесения на это среднее. Процедура нормализации может быть выполнена несколькими различными способами:\n",
    "\n",
    "1. Локально по произнесению (вычисляем среднее в некоторой окрестности (обычно 300 фреймов) каждого фрейма стека признаков и нормализуем на них этот фрейм).\n",
    "\n",
    "2. Глобально по произнесению (вычисляем среднее один раз по всей сессии и нормализуем на них все фреймы сессии).\n",
    "\n",
    "3. глобально по базе данных (вычисляем среднее общее для всех сессий в тренировочной базе данных и нормализуем на них все фреймы всех сессий).\n",
    "\n",
    "Иногда процедура нормализации сопровождается процедурой *масштабирования акустических признаков*. Процедура масштабирования признаков может быть выполнена теми же способами, что и процедура нормализации. Отличие процедуры масштабирования признаков от процедуры нормализации состоит в том, что при её выполнении необходимо вычислить не средний вектор акустических признаков, а вектор среднеквадратического отклонения, на который необходимо поэлементно разделить каждый нормализованный вектор акустических признаков некоторого произнесения.\n",
    "\n",
    "Предполагая, что набор акустических признаков до выполнения процедур нормализации и масштабирования был задан функцией $|X(k, m)|$, а после выполнения данных процедур – $|X_{norm}(k, m)|$, запишем следующее выражение:\n",
    "\n",
    "$$|X_{norm}(k, m)| = \\frac{|X_{norm}(k, m)| - m_X}{\\sigma_X},$$\n",
    "\n",
    "где $m_X$ – это средний вектор акустических признаков, $\\sigma_X$ – это вектор среднеквадратического отклонения акустических признаков, $k$ и $m$ имеют суть частоты и времени (k – номер спектральной составляющей, а m – это номер фрейма).\n",
    "\n",
    "В рамках настоящего пункта требуется выполнить процедуры нормализации и масштабирования по отношению к логарифмам энергий на выходе банка фильтров и мел-частотным кепстральным коэффициентам, вычисленным для некоторой звукозаписи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Построить распределение первых 3 компонент полученных акустических признаков для мужских и женских голосов**\n",
    "\n",
    "Для того, чтобы грубо проверить правильность расчёта акустических признаков выше, построим гистограммы распределения первых 3 компонент логарифмов энергий на выходе банка фильтров и мел-частотных кепстральных коэффициентов по некоторой базе данных. Рассмотрим в качестве этой базы звукозаписи мужских и женских голосов дикторов, список которых представлен в **./metadata/meta.txt**. В указанном файле перечислен список из 20 звукозаписей (10 для дикторов женского пола и 10 для дикторов мужского пола) из базы VoxCeleb1 test set с указанием пути до них, идентификационного номера диктора и пола диктора.\n",
    "\n",
    "Используя звукозаписи, список которых перечислен в **./metadata/meta.txt**, выполнить построение гистограмм распределения первых 3 компонент логарифмов энергий на выходе банка фильтров и мел-частотных кепстральных коэффициентов отдельно для базы мужских и женских голосов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Контрольные вопросы**\n",
    "\n",
    "1. Какие способы представления сигналов существуют?\n",
    "\n",
    "2. Что такое спектр Фурье (амплитудный и фазовый)?\n",
    "\n",
    "3. Что такое оконное преобразование Фурье?\n",
    "\n",
    "4. Что такое спектрограмма?\n",
    "\n",
    "5. Как выполнить процедуру преэмфазиса?\n",
    "\n",
    "6. Описать процедуру вычисления акустических признаков.\n",
    "\n",
    "7. Для каких целей выполняются процедуры нормализации и масштабирования акустических признаков?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Список литературы**\n",
    "\n",
    "1. Hayes M.H. Schaum’s outlines of digital signal processing. McGraw-Hill, 2011 ([ссылка](http://index-of.co.uk/DSP-Collection/Hayes,%20M.H.,%20Schaum's%20Outline%20of%20Digital%20Signal%20Processing,%20McGraw-Hill,%201999.pdf)).\n",
    "\n",
    "2. Beigi H. Fundamentals of speaker recogniton. Springer, 2011 ([ссылка](https://www.springer.com/gp/book/9780387775913))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лабораторная работа №1. Информативные признаки речевых сигналов: извлечение признаков\n",
    "**Описание**:\n",
    "В рамках данной лабораторной работы вам предстоит познакомиться с процедурами предобработки речевых сигналов и извлечения информативных признаков. В данной работе вам предлагается научиться извлекать\n",
    "\n",
    "- Mel Filter Banks - кратковременные энергии мелчастотных полос\n",
    "- Mel Frequency Cepstral Coeffitients - Мел частотные кепстральные коэффициенты\n",
    "\n",
    "Признаки должны совпадать с соответствующими признаками, которые извлекаются в **torchaudio** (https://pytorch.org/audio/stable/transforms.html)\n",
    "\n",
    "**Данные**:\n",
    "В качестве данных для проведения исследования предлагается взять базу VoxCeleb1: http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html.\n",
    "\n",
    "**Задания**:\n",
    "1. Сделать preemphasis (фильтрация верхних частот). Проанализировать амлитудно-частотные спектры исходного и обработанного речевых участков сигналов\n",
    "2. Вычислить акустические признаки разных видов: FBs40 и MFCCs23.\n",
    "3. Выполнить локальное центрирование и масштабирование признаков (нормализация MVN).\n",
    "4. Построить распределение первых 3 компонент полученных признаков по всей базе отдельно по гендерам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preemphasis preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'waveform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-306e5f3183df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maudiofeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudiofeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_waveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudiofeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreemphasis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'waveform' is not defined"
     ]
    }
   ],
   "source": [
    "from audiofeatures import Audiofeatures\n",
    "processed_waveform = Audiofeatures.preemphasis(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mel Filter Banks computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-83d0f682189d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMFB40_FeaturesExctractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudiofeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MFB40'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMFB40\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMFB40_FeaturesExctractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wav_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media_new/data/novoselov/ITMO_labs/itmo_speaker_recognition_course/lab1/audiofeatures.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, wav_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \"\"\"\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MFB40_FeaturesExctractor = Audiofeatures(feats_type='MFB40')\n",
    "MFB40 = MFB40_FeaturesExctractor.extract('wav_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mel Frequency Cepstral Coeffitiens computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC_FeaturesExctractor = Audiofeatures(feats_type='MFCC')\n",
    "MFCC = MFCC_FeaturesExctractor.extract('wav_path')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
