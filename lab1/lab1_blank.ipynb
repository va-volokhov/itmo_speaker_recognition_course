{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Лабораторный практикум по курсу «Распознавание диктора», Университет ИТМО, 2021**\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лабораторная работа №1. Информативные признаки речевых сигналов: извлечение признаков**\n",
    "\n",
    "**Цель работы:** изучение процедуры построения информативных акустических признаков для речевых сигналов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание лабораторной работы**\n",
    "\n",
    "1. Выполнить процедуру высокочастотной фильтрации (преэмфазис) речевого сигнала.\n",
    "\n",
    "2. Вычислить акустические признаки разных видов.\n",
    "\n",
    "3. Выполнить локальные центрирование и масштабирование акустических признаков.\n",
    "\n",
    "4. Построить распределение первых 3 компонент полученных акустических признаков для мужских и женских голосов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "\n",
    "from common import download_dataset, extract_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Подготовка данных для обучения и тестирования детектора речевой активности**\n",
    "\n",
    "В ходе выполнения лабораторной работы необходимы данные для осуществления процедуры вычисления акустических признаков. Возьмём в качестве этих данных несколько звукозаписей голосов людей мужского и женского пола, сохраненных в формат *wav*, выбранных из корпуса [VoxCeleb1 test set](https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip). Данный корпус содержит 4,874 звукозаписи (частота дискретизации равна 16кГц) 40 дикторов мужского и женского пола, разговаривающих на английском языке.\n",
    "\n",
    "В рамках настоящего пункта требуется выполнить загрузку и распаковку звуковых wav-файлов из корпуса VoxCeleb1 test set.\n",
    "\n",
    "![Рисунок 1](https://analyticsindiamag.com/wp-content/uploads/2020/12/image.png \"VoxCeleb. Крупномасштабная аудиовизуальная база данных человеческой речи.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checksum successful vox1_test_wav.zip.\n"
     ]
    }
   ],
   "source": [
    "# Download VoxCeleb1 (test set)\n",
    "with open('../data/lists/datasets.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "download_dataset(lines, user='voxceleb1902', password='nx0bl2v2', save_path='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting of ../data/vox1_test_wav.zip is successful.\n"
     ]
    }
   ],
   "source": [
    "# Extract VoxCeleb1 test set\n",
    "extract_dataset(save_path='../data/voxceleb1_test', fname='../data/vox1_test_wav.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Выполнить процедуру высокочастотной фильтрации (преэмфазис) речевого сигнала**\n",
    "\n",
    "Можно добавить краткую теорию про преэмфазис. Краткое описание того, что нужно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Вычислить акустические признаки разных видов**\n",
    "\n",
    "Можно добавить краткую теорию про вычисление логарифмов энергий на выходе мел-банка фильтров размерности 40 и мел-частотные кепстральные коэффициенты размерности 23. Краткое описание того, что нужно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Выполнить локальные центрирование и масштабирование акустических признаков**\n",
    "\n",
    "Можно добавить краткую теорию про выполнения процедур нормализации и масштабирования. Краткое описание того, что нужно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Построить распределение первых 3 компонент полученных акустических признаков для мужских и женских голосов**\n",
    "\n",
    "Краткое описание того, что нужно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Контрольные вопросы**\n",
    "\n",
    "1. Какие способы представления сигналов существуют?\n",
    "\n",
    "2. Что такое спектр Фурье (амплитудный и фазовый)?\n",
    "\n",
    "3. Что такое оконное преобразование Фурье?\n",
    "\n",
    "4. Что такое спектрограмма?\n",
    "\n",
    "5. Как выполнить процедуру преэмфазиса?\n",
    "\n",
    "6. Описать процедуру вычисления акустических признаков.\n",
    "\n",
    "7. Для каких целей выполняются процедуры нормализации и масштабирования акустических признаков?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Список литературы**\n",
    "\n",
    "1. Hayes M.H. Schaum’s outlines of digital signal processing. McGraw-Hill, 2011 ([ссылка](http://index-of.co.uk/DSP-Collection/Hayes,%20M.H.,%20Schaum's%20Outline%20of%20Digital%20Signal%20Processing,%20McGraw-Hill,%201999.pdf)).\n",
    "\n",
    "2. Beigi H. Fundamentals of speaker recogniton. Springer, 2011 ([ссылка](https://www.springer.com/gp/book/9780387775913))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лабораторная работа №1. Информативные признаки речевых сигналов: извлечение признаков\n",
    "**Описание**:\n",
    "В рамках данной лабораторной работы вам предстоит познакомиться с процедурами предобработки речевых сигналов и извлечения информативных признаков. В данной работе вам предлагается научиться извлекать\n",
    "\n",
    "- Mel Filter Banks - кратковременные энергии мелчастотных полос\n",
    "- Mel Frequency Cepstral Coeffitients - Мел частотные кепстральные коэффициенты\n",
    "\n",
    "Признаки должны совпадать с соответствующими признаками, которые извлекаются в **torchaudio** (https://pytorch.org/audio/stable/transforms.html)\n",
    "\n",
    "**Данные**:\n",
    "В качестве данных для проведения исследования предлагается взять базу VoxCeleb1: http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html.\n",
    "\n",
    "**Задания**:\n",
    "1. Сделать preemphasis (фильтрация верхних частот). Проанализировать амлитудно-частотные спектры исходного и обработанного речевых участков сигналов\n",
    "2. Вычислить акустические признаки разных видов: FBs40 и MFCCs23.\n",
    "3. Выполнить локальное центрирование и масштабирование признаков (нормализация MVN).\n",
    "4. Построить распределение первых 3 компонент полученных признаков по всей базе отдельно по гендерам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preemphasis preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'waveform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-306e5f3183df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maudiofeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudiofeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_waveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudiofeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreemphasis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'waveform' is not defined"
     ]
    }
   ],
   "source": [
    "from audiofeatures import Audiofeatures\n",
    "processed_waveform = Audiofeatures.preemphasis(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mel Filter Banks computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-83d0f682189d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMFB40_FeaturesExctractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudiofeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MFB40'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMFB40\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMFB40_FeaturesExctractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wav_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media_new/data/novoselov/ITMO_labs/itmo_speaker_recognition_course/lab1/audiofeatures.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, wav_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \"\"\"\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MFB40_FeaturesExctractor = Audiofeatures(feats_type='MFB40')\n",
    "MFB40 = MFB40_FeaturesExctractor.extract('wav_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mel Frequency Cepstral Coeffitiens computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC_FeaturesExctractor = Audiofeatures(feats_type='MFCC')\n",
    "MFCC = MFCC_FeaturesExctractor.extract('wav_path')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
