{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f4cabff",
   "metadata": {},
   "source": [
    "**Лабораторный практикум по курсу «Распознавание диктора», Университет ИТМО, 2021**\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ff96e",
   "metadata": {},
   "source": [
    "**Лабораторная работа №5. Адаптация и калибровка системы распознавания диктора**\n",
    "\n",
    "**Цель работы:** изучение методов адаптации и калибровки, используемых на практике при решении задачи голосовой биометрии.\n",
    "\n",
    "**Краткое описание:** в рамках настоящей лабораторной работы предлагается изучить и реализовать некоторые алгоритмы адаптации и калибровки биометрических систем. В качестве процедур адаптации предлагается рассмотреть адаптацию путём нормализации дикторских эмбеддингов с использованием среднего эмбеддинга, а также адаптацию на основе s-нормализации. Процедуру калибровки предлагается реализовать с помощью метода логистической регрессии. Тестирование системы голосовой биометрии после выполнения процедур адаптации и калибровки предлагается выполнить на основе метрики равновероятной ошибки применительно к задаче верификации.\n",
    "\n",
    "**Данные:** в качестве данных для выполнения лабораторной работы предлагается использовать тестовую часть базы\n",
    "[VoxCeleb1](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html) и [VoxCeleb2](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html)\n",
    "\n",
    "**Содержание лабораторной работы**\n",
    "\n",
    "1.\tПодготовка данных для выполнения процедуры адаптации.  \n",
    "\n",
    "2.\tРеализация процедуры адаптации с использованием центрирования дикторских эмбеддингов на средний эмбеддинг.  \n",
    "\n",
    "3.\tРеализация процедуры адаптации с использованием s-нормализации.  \n",
    "\n",
    "4.\tТестирование адаптированной к некоторым условиям биометрической системы.  \n",
    "\n",
    "5.\tПодготовка данных для выполнения процедуры калибровки.  \n",
    "\n",
    "6.\tРеализация простейшего алгоритма для выполнения процедуры калибровки системы голосовой биометрии.  \n",
    "\n",
    "7.\tТестирование калиброванной системы голосовой биометрии.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a241fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython extension to reload modules before executing user code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import of modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from math import sqrt, pi\n",
    "from matplotlib.pyplot import hist, plot, show, grid, title, xlabel, ylabel, legend, axis, imshow\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "import glob\n",
    "\n",
    "import common\n",
    "from common import download_dataset, extract_dataset, download_protocol, run_voxceleb_convert, part_extract\n",
    "from common import get_voxceleb_filelist\n",
    "from common import test_dataset_loader\n",
    "from common import extract_features, compute_scores_cosine\n",
    "from common import get_eer\n",
    "from common import concatenate\n",
    "from common import tsne\n",
    "from LoadModel import load_model\n",
    "from ResNetSE34V2 import MainModel\n",
    "\n",
    "from exercises import plot_histograms_2sets, mean_embd_norm, s_norm, get_tar_imp_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e733c6e1",
   "metadata": {},
   "source": [
    "**1. Подготовка тестовых данных и протокола для проведения тестирования системы верификации диктора**\n",
    "\n",
    "В ходе выполнения лабораторной работы необходимы *тестовые данные*, а также связанный с ними *протокол тестирования*. Данные представляют собой звукозаписи голосов людей мужского и женского пола, сохраненных в формат *wav*. Протокол тестирования организован в виде текстового файла, в каждой строчке которого содержится одна таргет- или импостор-попытка сравнения эталонной и тестовой звукозаписи (рассматривается задача *верификации диктора*, т.е. сравнение «один к одному»). Голоса эталона и теста из *таргет-попытки* (метка «1») соответствуют одному и тому же диктору, а голоса эталона и теста из *импостор-попытки* (метка «0») соответствуют разным дикторам.\n",
    "\n",
    "Необходимые данные можно скачать по ссылкам, представленным ниже:\n",
    "\n",
    "1. Выполнить загрузку и распаковку звуковых wav-файлов базы [VoxCeleb1 test set](https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip) и [VoxCeleb2 test set](https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_test_wav.zip).\n",
    "\n",
    "2. Преобразовать базу [VoxCeleb2 test set](https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_test_wav.zip) из aac в wav.\n",
    "\n",
    "3. Выполнить загрузку протокола тестирования [VoxCeleb1-O cleaned](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test2.txt).\n",
    "\n",
    "4. Подготовить тестовые и адаптационные *in-domain* данные путем эмулирования телефонного канала. В качестве тестовых рассматриваем данные полученные из базы VoxCeleb1 test set, в качестве адаптационных – из базы VoxCeleb2 test set.\n",
    "\n",
    "![Рисунок 1](https://analyticsindiamag.com/wp-content/uploads/2020/12/image.png \"VoxCeleb. Крупномасштабная аудиовизуальная база данных человеческой речи.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download VoxCeleb1 (test set)\n",
    "with open('../data/lists/datasets.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "download_dataset(lines, user='voxceleb1902', password='nx0bl2v2', save_path='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5008dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download VoxCeleb2 (test set)\n",
    "with open('../data/lists/datasets2.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "download_dataset(lines, user='voxceleb1902', password='nx0bl2v2', save_path='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb91462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract VoxCeleb1 test set and VoxCeleb2 test set\n",
    "extract_dataset(save_path='../data/voxceleb1_test', fname='../data/vox1_test_wav.zip')\n",
    "extract_dataset(save_path='../data/voxceleb2_test', fname='../data/vox2_test_aac.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we need rirs for reverberation\n",
    "with open('../data/lists/augment_datasets.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "download_dataset(lines, user=None, password=None, save_path='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac4a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_extract(save_path='../data', fname='../data/rirs_noises.zip', target=['RIRS_NOISES/simulated_rirs/mediumroom', 'RIRS_NOISES/simulated_rirs/smallroom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435afd75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def aac_to_wav(infile, outfile):\n",
    "    common.aac_to_wav(infile, outfile)\n",
    "\n",
    "# Prepare voxceleb2 : convert from aac to wav format\n",
    "run_voxceleb_convert(input_path='../data/voxceleb2_test/aac',\n",
    "                     result_path='../data/voxceleb2_test/wav',\n",
    "                     fun=aac_to_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a056ddb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_in_domain(infile, outfile, rir_list):\n",
    "    common.reverberate(infile, outfile, rir_list)\n",
    "#     common.apply_mp3_codec(infile, outfile)\n",
    "\n",
    "rir_path          = '../data/RIRS_NOISES/simulated_rirs'\n",
    "rirs = glob.glob(os.path.join(rir_path, '*/*/*.wav'));\n",
    "    \n",
    "f = partial(convert_to_in_domain, rir_list=rirs)\n",
    "\n",
    "run_voxceleb_convert(input_path='../data/voxceleb1_test/wav',\n",
    "                     result_path='../data/voxceleb1_test/wav_reverb',\n",
    "                     fun=f,\n",
    "                     threads=10)\n",
    "run_voxceleb_convert(input_path='../data/voxceleb2_test/wav',\n",
    "                     result_path='../data/voxceleb2_test/wav_reverb',\n",
    "                     fun=f,\n",
    "                     threads=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download VoxCeleb1-O cleaned protocol\n",
    "with open('../data/lists/protocols.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "download_protocol(lines, save_path='../data/voxceleb1_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a17756",
   "metadata": {},
   "source": [
    "**2. Вычисление дикторских моделей для эталонных и тестовых звукозаписей используемого протокола**\n",
    "\n",
    "Итого, мы имеем 2 тестовые базы:\n",
    "\n",
    "- *out-of-domain*: исходная тестовая база VoxCeleb1_test в микрофонном канале;\n",
    "- *in-domain*: целевая тестовая база in-domain в телефонном канале – VoxCeleb1 test set, полученная эмулированием телефонного канала.\n",
    "\n",
    "Аналогично предыдущей лабораторной работе, построим дикторские модели для наших тестовых баз с использованием предобученной нейронной сети и оценим ее качество на наших in-domain и out-of-domain данных. Для этого необходимо:\n",
    "\n",
    "1. Описать и инициализировать модель для генерации дикторских эмбеддингов.\n",
    "2. Вгрузить в инициализированную модель обученные веса.\n",
    "3. Вычислить эмбеддинги для эталонных и тестовых звукозаписей из исходной базы out-of-domain.\n",
    "4. Повторить п.3 для второй тестовой базы in-domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885652b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = MainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "with open('../data/lists/models.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "        \n",
    "model = load_model(model, lines, save_path='../data/models')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274117cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test protocol\n",
    "with open('../data/voxceleb1_test/veri_test2.txt', 'r') as f:\n",
    "    protocol = f.readlines()\n",
    "\n",
    "# Get a list of unique file names\n",
    "files = list(itertools.chain(*[x.strip().split()[-2:] for x in protocol]))\n",
    "setfiles = list(set(files))\n",
    "setfiles.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5f8f7",
   "metadata": {},
   "source": [
    "Построим эмбеддинги для исходной базы VoxCeleb1 test - out-of-domain тестовой базы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848afea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test data loader\n",
    "test_dataset = test_dataset_loader(setfiles, test_path='../data/voxceleb1_test/wav', eval_frames=500, num_eval=1)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8, drop_last=False, sampler=None)\n",
    "\n",
    "# Extract features for every image\n",
    "feats_out_of_domain = extract_features(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4a4bc",
   "metadata": {},
   "source": [
    "Построим эмбеддинги для in-domain тестовой базы (протокол остался прежним, имена файлов тоже, поэтому список setfiles не изменился)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test data loader\n",
    "test_dataset = test_dataset_loader(setfiles, test_path='../data/voxceleb1_test/wav_reverb', eval_frames=500, num_eval=1)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8, drop_last=False, sampler=None)\n",
    "\n",
    "# Extract features for every image\n",
    "feats_in_domain = extract_features(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4a2f7",
   "metadata": {},
   "source": [
    "**3. Формирование оценок сравнения эталонных и тестовых дикторских моделей**\n",
    "\n",
    "Для того, чтобы автоматически принять решении о принадлежности пары сравнения «эталон-тест» к таргет- или импостор-попытке, необходимо сформировать *оценку сравнения* между эталонной и тестовой дикторскими моделями, иначе мы называем их scores (скоры). В простейшем случае подобные сравнения можно выполнить с использованием *евклидовой метрики*, *косинусной метрики* и т.п.\n",
    "\n",
    "В рамках настоящего пункта необходимо выполнить следующее:\n",
    "\n",
    "1. Выполнить формирование оценок сравнения эталонных и дикторских моделей с использованием любой подходящей метрики (евклидово расстояние, косинусное расстояние и т.п.).\n",
    "\n",
    "2. Сформировать списки оценок сравнения, таргет-/импостор-меток и имен эталон-тест в триальных сравнениях.\n",
    "\n",
    "3. Получить оценки EER и построить графики распределения для тестовых баз in-domain и out-of-domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40271963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores between enroll and test speaker models\n",
    "# For in domain and out of domain data\n",
    "all_scores_in_domain, all_labels_in_domain, all_trials_in_domain = compute_scores_cosine(feats_in_domain, protocol)\n",
    "all_scores_out_of_domain, all_labels_out_of_domain, all_trials_out_of_domain = compute_scores_cosine(feats_out_of_domain, protocol)\n",
    "\n",
    "\n",
    "# Compute target and impostor histogram\n",
    "plot_histograms_2sets(all_scores_in_domain, all_labels_in_domain,\n",
    "                      all_scores_out_of_domain, all_labels_out_of_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85957791",
   "metadata": {},
   "source": [
    "**4. Доменная адаптация**\n",
    "\n",
    "*Доменная адаптация* рассматривается как проблема настройки параметров модели для случая когда существует большой объём нецелевых данных (out-of-domain data, source data) и малый объём размеченных или неразмеченных целевых данных (in-domain data, target data). В научно-технической литературе по распознаванию диктора часто выделяют следующие адаптационные техники: вычитание среднего, s-норма, CORAL, CORAL+, GRL, MultiReader и т.п. Важно отметить, что доменная адаптация может выполняться на всех этапах конвейера голосовой биометрии, то есть на этапе предобработки, диаризации, построения дикторской модели и т.п.\n",
    "\n",
    "В рамках настоящей лабораторной работы рассматриваются два классических для области распознавания диктора метода адаптации: вычитание среднего и s-нормализация. \n",
    "\n",
    "**4.1. Адаптация на основе вычитания среднего**\n",
    "\n",
    "Рассмотрим подход адаптации на основе вычитания среднего на уровне эмбеддингов, сгенерированных с использованием нейросетевой модели, обученной на нецелевых данных. Основные этапы данного подхода описаны ниже:\n",
    "\n",
    "1. Рассмотрим верификационный протокол тестирования, в котором эталонные и тестовые звукозаписи соответствуют одним и тем же целевым условиям.\n",
    "2. Вычислим эталонные и тестовые дикторские эмбеддинги с использованием имеющейся нейросетевой модели.\n",
    "3. Подготовим адаптационное множество данных, соответствующее целевым условиям.\n",
    "4. Вычислим дикторские эмбеддинги, имеющейся нейросетевой моделью, для данных из адаптационного множества и рассчитаем для него средний дикторский эмбеддинг.\n",
    "5. Центрируем эталонные и тестовые дикторские эмбеддинги на средний дикторский эмбеддинг адаптационного множества.\n",
    "6. Подготовим модель сравнения дикторских эмбеддингов и выполним сравнение центрированных эталонных и тестовых дикторских эмбеддингов.\n",
    "\n",
    "Собственно, этапы, описанные выше, и нужно реализовать в рамках настоящего пункта. Ниже предполагается, что адаптационное множество построено на основе базы VoxCeleb2 test set, а тестирование будет выполнено на основе базы VoxCeleb1 test set по отношению к протоколу VoxCeleb1-O cleaned. При при проведении тестов в одном случае база VoxCeleb1 test set будет рассматривается в оригинальном виде, а в другом – в искажённом, в котором предполагается, что выбранное искажение моделирует целевые условия. Необходимо отметить, что поскольку, изначально, данные из базы VoxCeleb2 test set соответствуют условиям, в которых записана база VoxCeleb1 test set, то для использования базы VoxCeleb2 test set, в задаче адаптации применительно к верификационному тесту на искаженных данных базы VoxCeleb1 test set, необходимо подвергнуть её искажениям, соответствующим целевым условиям. Подобная процедура выполнена выше в обном из пунктов лабораторной работы. Итогом выполнения настоящего пункта является оценка качества полученного после адаптации к целевым условиям верификационного решения. Качество предлагается проанализировать с использованием метрики EER и гистограмм распределения таргет- и импостор-оценок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "setfiles = get_voxceleb_filelist(input_path='../data/voxceleb2_test/wav_reverb')\n",
    "setfiles.sort()\n",
    "\n",
    "# Define test data loader\n",
    "adapt_dataset = test_dataset_loader(setfiles, test_path='../data/voxceleb2_test/wav_reverb', eval_frames=1000, num_eval=1)\n",
    "adapt_loader  = torch.utils.data.DataLoader(adapt_dataset, batch_size=1, shuffle=False, num_workers=8, drop_last=False, sampler=None)\n",
    "\n",
    "# Extract features for every image\n",
    "feats_adapt = extract_features(model, adapt_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_dict = {'in_domain': feats_in_domain,\n",
    "             'out_of_domain': feats_out_of_domain,\n",
    "                          'adapt': feats_adapt,\n",
    "             #              'in_domain_adapt': feats_in_domain_adapted,\n",
    "             #              'out_domain_adapt': feats_out_of_domain_adapted\n",
    "             }\n",
    "tsne(tsne_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5019ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_in_domain_adapted = mean_embd_norm(feats_in_domain, feats_adapt)\n",
    "# if we adapt out of domain data we will have worse results:\n",
    "# feats_out_of_domain_adapted = mean_embd_norm(feats_out_of_domain, feats_adapt)\n",
    "feats_adapt_centered = mean_embd_norm(feats_adapt, feats_adapt)\n",
    "\n",
    "# Compute scores between enroll and test speaker models\n",
    "# For in domain and out of domain data\n",
    "all_scores_in_domain, all_labels_in_domain, all_trials_in_domain = compute_scores_cosine(feats_in_domain_adapted, protocol)\n",
    "all_scores_out_of_domain, all_labels_out_of_domain, all_trials_out_of_domain = compute_scores_cosine(feats_out_of_domain, protocol)\n",
    "\n",
    "\n",
    "# Compute target and impostor histogram\n",
    "plot_histograms_2sets(all_scores_in_domain, all_labels_in_domain,\n",
    "                      all_scores_out_of_domain, all_labels_out_of_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e7e96",
   "metadata": {},
   "source": [
    "**4.2. Адаптация на основе s-нормы**\n",
    "\n",
    "Адаптация с помощью s-нормы предполагает выполнение процедуры нормализации оценок сравнения эталонов и тестов с целью уменьшения вариативности в попытках сравнения, которое ведёт к более лучшей калибровке и более надёжному выбору порога принятия решения. При выполнении адаптации на основе s-нормы необходимо выполнить следующую последовательность действий:\n",
    "\n",
    "1. Выполнить сравнение эталонной и тестовой дикторских моделей в рамках одной попытки, получив оценку.\n",
    "2. Ввести в рассмотрение импосторную когорту, состоящую из дикторских моделей, которые не пересекаются, в смысле дикторских меток, с эталонной и тестовой моделями в рамках одной попытки.\n",
    "3. Сравнить эталонную дикторскую модель с каждой моделью из импосторной когорты, получив оценки сравнения; упорядочить оценки сравнения по убыванию схожести моделей; выбрать первые $N$ оценок (самые сложные оценки сравнения) и вычислить для них среднее, $\\mu_e$, и среднеквадратическое отклонение, $\\sigma_e$.\n",
    "4. Повторить процедуру выше для тестовой дикторской модели, получив значения $\\mu_t$ и $\\sigma_t$.\n",
    "5. Выполнить нормализацию оценки сравнения $S$ для рассматриваемой попытки: $\\hat{S}=\\frac{S - \\mu_e}{2\\sigma_e} + \\frac{S - \\mu_t}{2\\sigma_t}$.\n",
    "\n",
    "В рамках настоящего пункта необходимо реализовать этапы, описанные выше. Как и ранее, предполагается, что данные из базы VoxCeleb2 test set будут использоваться в качестве адаптационного множества. Поскольку основу адаптации с помощью s-нормы составляет импосторная когорта, то искажённые под целевые условия данные из базы VoxCeleb2 test set в рамках настоящего пункта предполагается использовать для построения этой когорты. При при проведении тестов в одном случае база VoxCeleb1 test set будет рассматривается в оригинальном виде, а в другом – в искажённом, в котором предполагается, что выбранное искажение моделирует целевые условия. Итогом выполнения настоящего пункта является оценка качества полученного после адаптации к целевым условиям верификационного решения. Качество предлагается проанализировать с использованием метрики EER и гистограмм распределения таргет- и импостор-оценок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7034ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_in_domain, all_labels_in_domain, all_trials_in_domain = s_norm(feats_in_domain, protocol, feats_adapt, N_s=100, eps=0.6)\n",
    "all_scores_out_of_domain, all_labels_out_of_domain, all_trials_out_of_domain = s_norm(feats_out_of_domain, protocol, feats_adapt, N_s=100, eps=0.6)\n",
    "# Compute target and impostor histogram\n",
    "plot_histograms_2sets(all_scores_in_domain, all_labels_in_domain,\n",
    "                      all_scores_out_of_domain, all_labels_out_of_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72bcb50",
   "metadata": {},
   "source": [
    "**5. Калибровка системы голосовой биометрии**\n",
    "\n",
    "Результатом процедуры сравнения дикторских моделей являются «сырые» оценки сравнения. Основными проблемами при использовании «сырых» оценок являются:\n",
    "\n",
    "1. Порог принятия решения для выбранной рабочей точки полностью привязан к системе распознавания диктора (если существует $N$ систем, то существует $N$ порогов).\n",
    "2. Для произвольной выходной оценки сравнения нет информации о вероятности принадлежности к статистическим гипотезам.\n",
    "3. Сложно учесть влияние параметров качества речевого сигнала на выходные оценки.\n",
    "\n",
    "*Калибровка* является решением указанных проблем. Необходимость калибровки в сообществе по распознаванию диктора обусловлена следующим:\n",
    "\n",
    "1. Представление оценок сравнения в калиброванном виде для конкурсов, например, NIST SRE. Качество калибровки учитывается наравне с качеством верификации.\n",
    "2. В коммерческих системах распознавания по голосу, так как на практике для заданной оценки сравнения важно знать вероятность статистической гипотезы.\n",
    "\n",
    "В простейшем случае модель калибровки для системы распознавания диктора может быть описаны в виде линейной функциональной зависимости: $S_c = aS + b$. Здесь $a$ и $b$ – это параметры линейной модели калибровки, $S$ – это «сырое» значение оценки сравнения, а $S_c$ – значение оценки сравнения после калибровки.\n",
    "\n",
    "Для обучения параметров $a$ и $b$ линейной модели калибровки можно воспользоваться стоимостной функцией для *логистической регресии*. Можно доказать, что при решении задачи верификации апостериорная вероятность принадлежности пары сравнения «эталон-тест» к таргет-паре (нулевая гипотеза, $H_0$) для заданного значения калиброванной оценки сравнения эталона и теста может быть выражена следующим образом: $P(H_0|S_c) = \\frac{1}{1 + e^{-S_c + T_{act}^{LLR}}}$. Здесь $T_{act}^{LLR}$ – это величина оптимального порога принятия решения в пространстве логарифма отношения правдоподобия. Фактически, величина $T_{act}^{LLR}$ задаёт желаемую теоретически рабочую точку биометрической системы. Обычно в научно-технической литературе по распознаванию диктора величина $T_{act}^{LLR}$ задается в следующем виде: $T_{act}^{LLR} = ln\\left ( \\frac{1 - P(H_0)}{P(H_0)} \\right )$. Здесь $P(H_0)$ – это априорная вероятность таргет-гипотезы. Аналогичным образом, что и выше, можно записать апостериорную вероятность принадлежности пары сравнения «эталон-тест» к импостор-паре (альтернативная гипотеза, $H_1$) для заданного значения калиброванной оценки сравнения эталона и теста: $P(H_1|S_c) = \\frac{1}{1 + e^{S_c - T_{act}^{LLR}}}$. Предполагая, что априорные вероятность выпадения таргет- и импостор-попыток равны $P(H_0)$ и $P(H_1)$, соответственно, можно записать следующее выражение для стоимостной функции, которая позволит путём численной оптимизации, вычислить оптимальные значения параметров $a$ и $b$ через минимизацию стоимостной функции:\n",
    "\n",
    "$$J(a,b) = \\frac{P(H_0)}{N_0}\\sum_{i=1}^{N_0}ln\\left ( 1 + e^{-(aS_i + b) + T_{act}^{LLR}} \\right ) + \\frac{1 - P(H_0)}{N_1}\\sum_{i=1}^{N_1}ln\\left ( 1 + e^{aS_i + b - T_{act}^{LLR}} \\right ),$$\n",
    "\n",
    "где $N_0$ и $N_1$ – это количество таргет- и импостор-пар в калибровочном протоколе тестирования для верификации, который необходимо подготовить отдельно перед обучением калибровочной модели. Попытки сравнения «эталон-тест» в калибровочном протоколе должны быть схожими с теми, что будут встречаться при практическом использовании итоговой системы распознавания диктора, в смысле длительностей эталонной и тестовой звукозаписей, условий записи фонограмм и т.п.\n",
    "\n",
    "Для оценки качества модели калибровки системы голосовой биометрии можно воспользоваться подходом представленным ниже.\n",
    "\n",
    "Пусть в настоящей лабораторной работе *байесовский риск* задан в следующем виде: $\\overline{C} = P(D_1|H_0)P(H_0) + P(D_0|H_1)P(H_1)/P(H_0)$. Здесь $P(D_1|H_0)$ – это вероятность ошибки первого рода, а $P(D_0|H_1)$ – вероятность ошибки второго рода. Биометрическая система считается откалиброванной, если практический минимум байесовского риска, $\\overline{C}_{min}$, вычисленный в эмпирически подобранном пороге $T_{min}^{LLR}$ по отношению к некоторому протоколу тестирования для задачи верификации, совпадает с теоретическим минимум байесовского риска, $\\overline{C}_{act}$, вычисленным в точке $T_{act}^{LLR}$.\n",
    "\n",
    "В рамках настоящего пункта необходимо обучить линейную модель калибровки. Для решения указанной задачи необходимо выполнить следующие действия:\n",
    "\n",
    "1. Подготовить калибровочный протокол для обучения модели калибровки.\n",
    "2. Задать рабочую точку, которая определит величину $T_{act}^{LLR}$.\n",
    "3. Обучить калибровочную модель путём минимизации стоимостной функции для логистической регрессии с использованием методов численной оптимизации первого порядка.\n",
    "4. Посчитать значения $\\overline{C}_{min}$ и $\\overline{C}_{act}$, а также $T_{min}^{LLR}$ и $T_{act}^{LLR}$ для выбранных протоколов тестирования до выполнения и после выполнения процедуры калибровки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989dd78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download meta data for adapt_set datasets\n",
    "with open('../data/lists/protocols2.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "download_protocol(lines, save_path='../data/voxceleb2_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d577c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: finish it\n",
    "import CalibrationModel\n",
    "from CalibrationDataset import CalibrationDataset\n",
    "\n",
    "tar, imp = get_tar_imp_scores(all_scores_in_domain, all_labels_in_domain)\n",
    "test_set = CalibrationDataset(target_scores=tar, impostor_scores=imp)\n",
    "\n",
    "# generate adapt protocol\n",
    "meta_vox2 = pd.read_csv('../data/voxceleb2_test/vox2_meta.csv', sep=' ,')\n",
    "meta_vox2 = meta_vox2.rename(columns={\"VoxCeleb2 ID\": 'id', \"Gender\": \"gender\"})\n",
    "\n",
    "generate_protocol(adapt_dataset.test_list, adapt_dataset.test_list, meta_enroll=meta_vox2, meta_test=meta_vox2)\n",
    "\n",
    "tar, imp = get_tar_imp_scores(all_scores_in_domain, all_labels_in_domain)\n",
    "train_set = CalibrationDataset(target_scores=tar, impostor_scores=imp)\n",
    "\n",
    "calibration_model = CalibrationModel.LinearModel()\n",
    "train_calibration(calibration_model, train_set, test_set, system_name, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a7b8b",
   "metadata": {},
   "source": [
    "**7. Контрольные вопросы**\n",
    "\t\t\t\t\t\t\t\t\t\t\t\n",
    "1. Что такое доменная адаптация?\n",
    "2. Как выполнить процедуру адаптации через вычисление среднего дикторского эмбеддинга адаптационного множества?\n",
    "3. Как выполнить процедуру адаптации на основе s-нормализации?\n",
    "4. Для какой цели решается задача калибровки?\n",
    "5. Что такое «хорошая» калибровка?\n",
    "6. Какие модели калибровки систем голосовой биометрии рассматриваются на практике?\n",
    "7. Как обучить калибровочную модель с использованием метода логистической регресии?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015eb2b",
   "metadata": {},
   "source": [
    "**8. Список литературы**\n",
    "\n",
    "1. Matějka P., Novotný O., Plchot O., Burget L., Sánchez M.D., Černocký J. Analysis of score normalization in multilingual speaker recognition // Proc. Interspeech 2017, 2017. P. 1567–1571 ([ссылка](https://www.isca-speech.org/archive/pdfs/interspeech_2017/matejka17_interspeech.pdf)).\n",
    "\n",
    "2. Gusev A., Volokhov V., Vinogradova A., Andzhukaev T., Shulipa A., Novoselov S., Pekhovsky T., Kozlov A. STC-Innovation speaker recognition systems for far-field speaker verification challenge 2020 // Proc. Interspeech 2020, 2020. P. 3466–3470 ([ссылка](https://www.isca-speech.org/archive/pdfs/interspeech_2020/gusev20_interspeech.pdf)).\n",
    "\n",
    "3. Brümmer N., Villiers E. The BOSARIS toolkit: theory, algorithms and code for surviving the new DCF // arXiv:1304.2865 [stat.AP] ([ссылка](https://arxiv.org/pdf/1304.2865.pdf))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}